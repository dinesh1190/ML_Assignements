{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/YwX3hu93xZtctM3TFW9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupriyaSingh1997/ML_Assignment/blob/main/Assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the Bayesian interpretation of probability.\n",
        "\n",
        "The Bayesian interpretation of probability is a perspective that views probability as a measure of uncertainty or subjective belief. It is based on the ideas and principles formulated by Thomas Bayes, an 18th-century mathematician and philosopher.\n",
        "\n",
        "According to the Bayesian interpretation, probability is assigned to statements or propositions, representing a degree of belief or confidence in their truthfulness. In this view, probability is not seen as an inherent property of events or random processes, but rather as a reflection of the observer's state of knowledge or information.\n",
        "\n",
        "The Bayesian interpretation emphasizes the use of prior knowledge and evidence to update and revise beliefs in light of new information. It employs Bayes' theorem, which quantifies the relationship between the prior beliefs and the likelihood of observing certain data, to compute the posterior probability, which represents the updated belief after incorporating new evidence.\n",
        "\n",
        "In summary, the Bayesian interpretation of probability views probability as a measure of subjective belief, which can be updated using Bayes' theorem based on prior knowledge and new evidence. It provides a framework for reasoning under uncertainty and making decisions based on available information."
      ],
      "metadata": {
        "id": "RUhshe4gPrHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define probability of a union of two events with equation.\n",
        "\n",
        "The probability of the union of two events, denoted as A ∪ B, is the probability that either event A or event B or both occur. Mathematically, it can be expressed using the following equation:\n",
        "\n",
        "P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
        "\n",
        "where:\n",
        "\n",
        "P(A ∪ B) represents the probability of the union of events A and B.\n",
        "P(A) represents the probability of event A occurring.\n",
        "P(B) represents the probability of event B occurring.\n",
        "P(A ∩ B) represents the probability of the intersection of events A and B, i.e., the probability that both events A and B occur simultaneously.\n",
        "The equation accounts for the fact that when calculating the probability of the union, we add the probabilities of events A and B but then subtract the probability of their intersection to avoid double-counting. This ensures that we correctly account for the overlapping portion of the events.\n",
        "\n",
        "Note that for mutually exclusive events (i.e., events that cannot occur simultaneously), the probability of their intersection is zero (P(A ∩ B) = 0), and the equation simplifies to:\n",
        "\n",
        "P(A ∪ B) = P(A) + P(B)\n",
        "\n",
        "In this case, we simply add the probabilities of the individual events to obtain the probability of their union."
      ],
      "metadata": {
        "id": "U7GjvnEnPrEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is joint probability? What is its formula?\n",
        "\n",
        "Joint probability refers to the probability of two or more events occurring simultaneously. It measures the likelihood of the intersection of events A and B happening together.\n",
        "\n",
        "The formula for calculating joint probability depends on whether the events are independent or dependent.\n",
        "\n",
        "For independent events:\n",
        "If events A and B are independent, the joint probability is calculated as the product of their individual probabilities:\n",
        "\n",
        "P(A ∩ B) = P(A) * P(B)\n",
        "\n",
        "In this case, the probability of both events occurring is simply the product of their individual probabilities since independence implies that the occurrence of one event does not affect the occurrence of the other.\n",
        "\n",
        "For dependent events:\n",
        "If events A and B are dependent, the joint probability is calculated using the conditional probability:\n",
        "\n",
        "P(A ∩ B) = P(A | B) * P(B)\n",
        "Here, P(A | B) represents the probability of event A occurring given that event B has already occurred. The joint probability is obtained by multiplying this conditional probability by the probability of event B.\n",
        "\n",
        "It's important to note that the formula for joint probability can be extended to more than two events. For example, for three events A, B, and C, the joint probability would be:\n",
        "\n",
        "P(A ∩ B ∩ C) = P(A) * P(B | A) * P(C | A ∩ B)\n",
        "\n",
        "The joint probability provides valuable information about the relationship between events and is often used in various statistical analyses and probability models."
      ],
      "metadata": {
        "id": "HXmIOquhPrB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is chain rule of probability?\n",
        "\n",
        "The chain rule of probability, also known as the multiplication rule, is a fundamental principle in probability theory that allows us to compute the probability of multiple events occurring together. It enables us to express the joint probability of a series of events as a product of conditional probabilities.\n",
        "\n",
        "The chain rule states that the joint probability of multiple events can be calculated by multiplying the conditional probabilities of each event given the occurrence of the previous events in the chain.\n",
        "\n",
        "Mathematically, for a series of events A₁, A₂, ..., Aₙ, the chain rule of probability is given by:\n",
        "\n",
        "P(A₁ ∩ A₂ ∩ ... ∩ Aₙ) = P(A₁) * P(A₂ | A₁) * P(A₃ | A₁ ∩ A₂) * ... * P(Aₙ | A₁ ∩ A₂ ∩ ... ∩ Aₙ₋₁)\n",
        "\n",
        "In this formula, P(A₁) represents the probability of the first event A₁ occurring. Then, for each subsequent event Aᵢ, the conditional probability P(Aᵢ | A₁ ∩ A₂ ∩ ... ∩ Aᵢ₋₁) represents the probability of event Aᵢ occurring given that all previous events A₁, A₂, ..., Aᵢ₋₁ have occurred.\n",
        "\n",
        "The chain rule is especially useful when dealing with complex systems or events that depend on multiple factors or conditions. By breaking down the joint probability into a series of conditional probabilities, it allows us to calculate the overall probability of the entire sequence of events occurring.\n",
        "\n",
        "It is worth noting that the chain rule can be applied to both dependent and independent events, making it a versatile tool in probability calculations."
      ],
      "metadata": {
        "id": "a-pc69SpPq_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is conditional probability means? What is the formula of it?\n",
        "\n",
        "Conditional probability is a measure of the probability of an event occurring given that another event has already occurred. It represents the likelihood of event A happening, given that event B has occurred.\n",
        "\n",
        "The conditional probability is denoted as P(A | B), read as \"the probability of A given B.\" The vertical bar \"|\" indicates the conditioning or dependency on event B.\n",
        "\n",
        "The formula for calculating conditional probability is:\n",
        "\n",
        "P(A | B) = P(A ∩ B) / P(B)\n",
        "\n",
        "where:\n",
        "\n",
        "P(A | B) represents the conditional probability of event A given event B.\n",
        "P(A ∩ B) represents the joint probability of events A and B occurring together.\n",
        "P(B) represents the probability of event B occurring.\n",
        "The formula can be interpreted as the ratio of the joint probability of events A and B to the probability of event B. It quantifies the proportion of event B that satisfies event A.\n",
        "\n",
        "The conditional probability formula can be understood as adjusting the original probability of event A based on the occurrence of event B. By conditioning on event B, we restrict our sample space to only those outcomes where event B has occurred, and then we measure the proportion of those outcomes in which event A also occurs.\n",
        "\n",
        "It's important to note that the conditional probability formula assumes that event B has a nonzero probability (P(B) > 0). If P(B) = 0, the conditional probability is undefined, as division by zero is not possible.\n",
        "\n",
        "Conditional probability is a fundamental concept in probability theory and has applications in various fields, including statistics, machine learning, and decision-making, particularly when analyzing events that depend on each other."
      ],
      "metadata": {
        "id": "_hcA2SM7Pq9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are continuous random variables?\n",
        "\n",
        "Continuous random variables are variables in probability theory that can take on any value within a certain interval or range. Unlike discrete random variables, which can only take on specific isolated values, continuous random variables can assume any value within a continuous range.\n",
        "\n",
        "Examples of continuous random variables include measurements such as time, distance, temperature, weight, and height. These variables can theoretically have an infinite number of possible values within their respective ranges.\n",
        "\n",
        "The probability distribution of a continuous random variable is described by a probability density function (PDF). The PDF represents the relative likelihood of the variable taking on different values within the interval. The area under the PDF curve over a given interval corresponds to the probability of the variable falling within that interval.\n",
        "\n",
        "Properties of continuous random variables differ from those of discrete random variables. For instance, the probability of a continuous random variable taking on a specific value is typically zero since there are infinitely many possible values within any interval. Instead, probabilities are calculated for ranges or intervals of values.\n",
        "\n",
        "To determine probabilities for continuous random variables, integration techniques are used to calculate the area under the PDF curve over a given interval. This enables the calculation of probabilities associated with specific events or conditions related to the continuous variable.\n",
        "\n",
        "Continuous random variables play a crucial role in fields such as statistics, physics, engineering, economics, and many other areas where phenomena are measured on a continuous scale."
      ],
      "metadata": {
        "id": "hR_APnWhPq70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What are Bernoulli distributions? What is the formula of it?\n",
        "\n",
        "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success and failure. It is named after Jacob Bernoulli, a Swiss mathematician. The distribution is characterized by a single parameter, p, which represents the probability of success.\n",
        "\n",
        "The formula for the probability mass function (PMF) of a Bernoulli distribution is:\n",
        "\n",
        "P(X = x) = p^x * (1 - p)^(1 - x)\n",
        "\n",
        "where:\n",
        "\n",
        "P(X = x) represents the probability that the random variable X takes the value x.\n",
        "x is either 0 or 1, representing failure and success, respectively.\n",
        "p is the probability of success. It satisfies 0 ≤ p ≤ 1.\n",
        "The PMF evaluates to p when x = 1 (success) and to (1 - p) when x = 0 (failure). The PMF ensures that the probabilities sum up to 1, as there are only two possible outcomes.\n",
        "\n",
        "The expected value (mean) of a Bernoulli distribution is given by:\n",
        "\n",
        "E(X) = p\n",
        "\n",
        "This indicates that the average outcome of a Bernoulli experiment is equal to the probability of success.\n",
        "\n",
        "The variance of a Bernoulli distribution is given by:\n",
        "\n",
        "Var(X) = p * (1 - p)\n",
        "\n",
        "The variance measures the spread or dispersion of the distribution around the expected value.\n",
        "\n",
        "The Bernoulli distribution is commonly used to model binary events or situations where an outcome can be classified as either success or failure. Examples include coin flips, success or failure of a drug trial, or the occurrence or non-occurrence of an event.\n",
        "\n",
        "It is worth noting that the Bernoulli distribution is a special case of the binomial distribution, which extends to multiple independent Bernoulli trials. The binomial distribution describes the number of successes in a fixed number of independent Bernoulli trials."
      ],
      "metadata": {
        "id": "ynPzEDN7Pq5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is binomial distribution? What is the formula?\n",
        "\n",
        "The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials. It is named after the term \"binomial,\" which refers to the fact that it involves two possible outcomes: success and failure.\n",
        "\n",
        "The binomial distribution is characterized by two parameters: the number of trials, denoted as n, and the probability of success in each trial, denoted as p.\n",
        "\n",
        "The formula for the probability mass function (PMF) of the binomial distribution is:\n",
        "\n",
        "P(X = k) = C(n, k) * p^k * (1 - p)^(n - k)\n",
        "\n",
        "where:\n",
        "\n",
        "P(X = k) represents the probability that the random variable X takes the value k, which represents the number of successes.\n",
        "C(n, k) denotes the binomial coefficient, also known as \"n choose k,\" which represents the number of ways to choose k successes from n trials and is calculated as n! / (k! * (n - k)!).\n",
        "p is the probability of success in a single trial.\n",
        "(1 - p) represents the probability of failure in a single trial.\n",
        "n is the total number of trials.\n",
        "The expected value (mean) of a binomial distribution is given by:\n",
        "\n",
        "E(X) = n * p\n",
        "\n",
        "This indicates that the average number of successes in n trials is equal to the product of the number of trials and the probability of success in each trial.\n",
        "\n",
        "The variance of a binomial distribution is given by:\n",
        "\n",
        "Var(X) = n * p * (1 - p)\n",
        "\n",
        "The variance measures the spread or dispersion of the distribution around the expected value.\n",
        "\n",
        "The binomial distribution is commonly used to model situations where there are a fixed number of independent trials with a known probability of success. Examples include the number of heads obtained in a series of coin flips, the number of defective items in a production batch, or the number of correct answers on a multiple-choice test.\n",
        "\n",
        "It's important to note that the binomial distribution assumes that the trials are independent and that the probability of success remains constant across all trials."
      ],
      "metadata": {
        "id": "6nmZ-tshPq3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Poisson distribution? What is the formula?\n",
        "\n",
        "The Poisson distribution is a discrete probability distribution that models the number of events occurring in a fixed interval of time or space when the events are rare and randomly distributed. It is named after the French mathematician Siméon Denis Poisson.\n",
        "\n",
        "The Poisson distribution is characterized by a single parameter, denoted as λ (lambda), which represents the average rate or average number of events occurring in the given interval.\n",
        "\n",
        "The formula for the probability mass function (PMF) of the Poisson distribution is:\n",
        "\n",
        "P(X = k) = (e^(-λ) * λ^k) / k!\n",
        "\n",
        "where:\n",
        "\n",
        "P(X = k) represents the probability that the random variable X takes the value k, which represents the number of events.\n",
        "\n",
        "e is the base of the natural logarithm (approximately 2.71828).\n",
        "λ is the average rate or average number of events occurring in the given interval.\n",
        "k is a non-negative integer representing the number of events.\n",
        "The PMF calculates the probability of observing exactly k events in the interval based on the average rate λ. The term (e^(-λ) * λ^k) represents the probability of k events occurring, and k! (k factorial) accounts for the number of possible orderings of the events.\n",
        "\n",
        "The expected value (mean) of a Poisson distribution is given by:\n",
        "\n",
        "E(X) = λ\n",
        "\n",
        "This indicates that the average number of events in the given interval is equal to the average rate parameter λ.\n",
        "\n",
        "The variance of a Poisson distribution is also equal to λ:\n",
        "\n",
        "Var(X) = λ\n",
        "\n",
        "The Poisson distribution is commonly used to model rare events or phenomena where the occurrence of events is random and the average rate is known or estimated. Examples include the number of customer arrivals at a service counter, the number of phone calls received in a call center during a specific time period, or the number of emails received per day.\n",
        "\n",
        "It's important to note that the Poisson distribution assumes that the events occur independently and with a constant average rate λ throughout the interval of interest."
      ],
      "metadata": {
        "id": "c0__jspkPq1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Define covariance.\n",
        "\n",
        "Covariance is a statistical measure that quantifies the relationship between two random variables. It provides information about how the variables vary together or co-vary. In particular, covariance indicates the direction and magnitude of the linear relationship between the variables.\n",
        "\n",
        "Mathematically, the covariance between two random variables X and Y is defined as:\n",
        "\n",
        "Cov(X, Y) = E[(X - E(X))(Y - E(Y))]\n",
        "\n",
        "where:\n",
        "\n",
        "Cov(X, Y) represents the covariance between variables X and Y.\n",
        "E(X) and E(Y) denote the expected values (means) of X and Y, respectively.\n",
        "The formula calculates the expected value of the product of the deviations of X and Y from their respective means. A positive covariance indicates that the variables tend to increase or decrease together, while a negative covariance indicates that one variable tends to increase while the other decreases.\n",
        "\n",
        "The magnitude of the covariance is not standardized and depends on the scales of the variables. Therefore, it is difficult to compare covariances across different datasets.\n",
        "\n",
        "Covariance can take on various values, and its interpretation depends on the context and the scales of the variables being analyzed. To better understand the strength and direction of the relationship between variables, covariance is often normalized to a standard measure called correlation coefficient.\n",
        "\n",
        "It's worth noting that covariance measures only the linear relationship between variables and does not capture other types of relationships or dependencies. Additionally, covariance is sensitive to the scale of the variables and can be influenced by outliers in the data."
      ],
      "metadata": {
        "id": "FJiO-PdAPqyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Define correlation\n",
        "\n",
        "Correlation is a statistical measure that quantifies the strength and direction of the linear relationship between two random variables. It provides a standardized measure of the extent to which the variables are related to each other.\n",
        "\n",
        "The correlation coefficient, denoted by the symbol \"r,\" is used to represent the correlation between two variables. The correlation coefficient can take values between -1 and +1.\n",
        "\n",
        "A correlation coefficient of +1 indicates a perfect positive correlation, meaning that the variables have a strong linear relationship and tend to increase or decrease together.\n",
        "A correlation coefficient of -1 indicates a perfect negative correlation, meaning that the variables have a strong linear relationship, but they tend to move in opposite directions: when one variable increases, the other decreases.\n",
        "A correlation coefficient of 0 indicates no linear relationship or correlation between the variables.\n",
        "\n",
        "The correlation coefficient is calculated using the following formula:\n",
        "\n",
        "r = Cov(X, Y) / (σ(X) * σ(Y))\n",
        "\n",
        "where:\n",
        "\n",
        "Cov(X, Y) represents the covariance between variables X and Y.\n",
        "σ(X) and σ(Y) denote the standard deviations of variables X and Y, respectively.\n",
        "By dividing the covariance by the product of the standard deviations, the correlation coefficient is normalized to a range of -1 to +1, making it easier to compare correlations across different datasets.\n",
        "\n",
        "The correlation coefficient provides valuable insights into the relationship between variables. A strong positive or negative correlation indicates a high degree of association, while a correlation close to zero suggests little to no linear relationship. However, it's important to note that correlation measures only linear relationships and may not capture complex or nonlinear dependencies between variables.\n",
        "\n",
        "Correlation analysis is widely used in fields such as statistics, economics, finance, social sciences, and many others to understand and quantify the relationship between variables and to make predictions or inferences based on the observed correlations."
      ],
      "metadata": {
        "id": "9aAXxinHRToR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Define sampling with replacement. Give example.\n",
        "\n",
        "Sampling with replacement is a method in statistics and probability where, after selecting an individual from a population, that individual is placed back into the population before the next selection. In other words, each selected individual has an equal chance of being chosen again in subsequent selections.\n",
        "\n",
        "To illustrate this concept, let's consider an example:\n",
        "\n",
        "Suppose you have a bag containing five colored balls: two red balls (R), two blue balls (B), and one green ball (G). If you were to sample with replacement, the following steps would occur:\n",
        "\n",
        "You randomly select a ball from the bag without looking.\n",
        "Let's say you pick a blue ball (B).\n",
        "\n",
        "After recording the color of the selected ball, you return it to the bag.\n",
        "So, the blue ball (B) is put back into the bag, alongside the remaining balls.\n",
        "\n",
        "The bag now contains five balls again: two red balls (R), two blue balls (B), and one green ball (G).\n",
        "\n",
        "You repeat the process of randomly selecting a ball from the bag.\n",
        "This time, you might select a red ball (R).\n",
        "\n",
        "After recording the color of the selected ball, you return it to the bag again.\n",
        "So, the red ball (R) is placed back into the bag with the remaining balls.\n",
        "\n",
        "Sampling with replacement allows the same item to be chosen multiple times, which means that each selection is independent and unaffected by the previous selections. This method is commonly used when creating random samples or simulating random events in various statistical analyses and experiments."
      ],
      "metadata": {
        "id": "n2NrfMuHRTk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is sampling without replacement? Give example.\n",
        "\n",
        "Sampling without replacement is a method in statistics and probability where, after selecting an individual from a population, that individual is not returned to the population before the next selection. In other words, each selected individual is removed from the population, and the population size decreases with each selection.\n",
        "\n",
        "To illustrate this concept, let's consider an example:\n",
        "\n",
        "Suppose you have a deck of playing cards containing 52 cards. If you were to sample without replacement, the following steps would occur:\n",
        "\n",
        "You randomly select a card from the deck without looking.\n",
        "Let's say you pick the Ace of Spades.\n",
        "\n",
        "After recording the value and suit of the selected card, you remove it from the deck.\n",
        "So, the Ace of Spades is taken out of the deck, leaving 51 cards remaining.\n",
        "\n",
        "The deck now contains 51 cards: 4 Aces (one Ace of Spades removed) and 51 non-Ace cards.\n",
        "\n",
        "You repeat the process of randomly selecting a card from the remaining deck.\n",
        "This time, you might select the 10 of Hearts.\n",
        "\n",
        "After recording the value and suit of the selected card, you remove it from the deck.\n",
        "So, the 10 of Hearts is removed from the deck, leaving 50 cards remaining.\n",
        "\n",
        "Sampling without replacement ensures that each item can only be selected once. As a result, the probability of selecting a particular item changes with each selection because the population size decreases. The method is commonly used when creating representative samples or conducting experiments where it is important to avoid duplicate selections.\n",
        "\n",
        "Sampling without replacement can be seen in various applications, such as selecting participants for a survey or conducting experiments where the order of selection matters."
      ],
      "metadata": {
        "id": "NQAskwuBRTiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is hypothesis? Give example.\n",
        "\n",
        "In the context of scientific research and statistics, a hypothesis is a proposed explanation or statement that is subject to testing and investigation. It is a tentative proposition or educated guess about a phenomenon or relationship between variables.\n",
        "\n",
        "A hypothesis typically takes the form of a declarative statement and is used to guide research and formulate predictions. It serves as a starting point for conducting experiments or data analysis to gather evidence that either supports or refutes the hypothesis.\n",
        "\n",
        "Example:\n",
        "Let's consider an example related to the effect of exercise on sleep quality. Suppose you have a hypothesis that regular exercise improves sleep quality.\n",
        "\n",
        "Hypothesis: \"Regular exercise has a positive effect on sleep quality.\"\n",
        "\n",
        "In this example, the hypothesis suggests that engaging in regular exercise leads to better sleep quality. To test this hypothesis, a researcher might design a study where participants are divided into two groups: one group that engages in regular exercise and another group that does not. The researcher would then collect data on sleep quality, such as the duration and perceived quality of sleep, from both groups and compare the results.\n",
        "\n",
        "Based on the collected data, the researcher can analyze and evaluate whether the evidence supports or contradicts the initial hypothesis. If the data shows a significant improvement in sleep quality among those who engage in regular exercise compared to the control group, it would provide support for the hypothesis. Conversely, if there is no significant difference between the two groups, it would suggest that the hypothesis is not supported.\n",
        "\n",
        "Hypotheses are essential in scientific research as they guide the investigation, help generate testable predictions, and provide a framework for interpreting the results. They serve as a starting point for knowledge discovery and the formulation of theories in various fields of study."
      ],
      "metadata": {
        "id": "2lwUo57kRTf9"
      }
    }
  ]
}